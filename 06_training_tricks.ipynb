{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seminar6.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgGelUsnoxlW",
        "colab_type": "text"
      },
      "source": [
        "# Трюки для обучения нейронных сетей\n",
        "\n",
        "### **1. Аугментации**\n",
        "\n",
        "На практике часто оказывается, что нет достаточно большого количества размеченных данных, чтобы адекватно обучить модель, а общедоступные датасеты плохо приближают генеральную совокупность данных, возникающую в реальной задаче.\n",
        "\n",
        "Однако в таких ситуациях может оказаться полезным изменить объекты из доступной нам выборки. Например, если речь идёт о работе с изображениями, картинки — в зависимости от конкретной задачи — можно поворачивать, искривлять, накладывать дополнительные объекты, добавлять шум, менять яркость, расфокусировать и т. д.\n",
        "\n",
        "Многие из таких функций реализованы в [preprocessing.image](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image) из TensorFlow.\n",
        "\n",
        "Возьмём произвольный объект из датасета CIFAR-10:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LC7LYkcSokgJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "NUM_CLASSES = 10\n",
        "cifar10_classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \n",
        "                   \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDRZWvHkSF8o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "rand_index = np.random.randint(0, len(y_train))\n",
        "\n",
        "x_cur = x_train[rand_index,:]\n",
        "y_cur = y_train[rand_index, 0]\n",
        "\n",
        "def draw_image(x, y):\n",
        "  plt.imshow(x)\n",
        "  plt.title(cifar10_classes[y])\n",
        "  plt.show()\n",
        "  \n",
        "draw_image(x_cur, y_cur)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYJPXmIPVksI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tf.keras.preprocessing.image.apply_affine_transform(x_cur, theta=30)\n",
        "draw_image(x, y_cur)\n",
        "#Повернём картинку на 30 градусов"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3quPypzyZqPH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tf.keras.preprocessing.image.apply_affine_transform(x_cur, shear=35)\n",
        "draw_image(x, y_cur)\n",
        "#Наклоним картинку на 35 градусов"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNDvGZock8Qg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tf.keras.preprocessing.image.apply_brightness_shift(x_cur, 0.5)\n",
        "draw_image(x.astype(int), y_cur)\n",
        "#уменьшим яркость"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIS5Lcv1iIdX",
        "colab_type": "text"
      },
      "source": [
        "Попробуйте реализовать зеркальное отображение картинки относительно вертикальной оси (подсказка: в numpy есть функция для изменения порядка элементов в массиве на обратный по заданному измерению):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UpRrflymazB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def horizontal_reflect(image):\n",
        "  #YOUR CODE HERE\n",
        "\n",
        "draw_image(horizontal_reflect(x_cur), y_cur)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2QjMl7MZmz5",
        "colab_type": "text"
      },
      "source": [
        "Обучим на CIFAR-10 свёрточную нейронную сеть без аугментации (см. семинар 4)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00XDnF0NoAR0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train2 = x_train / 255 - 0.5\n",
        "x_test2 = x_test / 255 - 0.5\n",
        "\n",
        "y_train2 = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test2 = tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, LeakyReLU\n",
        "\n",
        "def make_model():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(filters=16, padding='same', kernel_size=(3,3), input_shape=(32,32,3)))\n",
        "    model.add(LeakyReLU(0.1))\n",
        "    model.add(Conv2D(filters=32, padding='same', kernel_size=(3,3)))  \n",
        "    model.add(LeakyReLU(0.1))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2), padding='same'))\n",
        "    model.add(Conv2D(filters=64, padding='same', kernel_size=(3,3)))  \n",
        "    model.add(LeakyReLU(0.1))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2), padding='same')) \n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256))                \n",
        "    model.add(LeakyReLU(0.1))\n",
        "    model.add(Dense(10))             \n",
        "    model.add(Activation(\"softmax\"))\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kiItBmfrJ-U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reset_tf_session():\n",
        "    curr_session = tf.get_default_session()\n",
        "    if curr_session is not None:\n",
        "        curr_session.close()\n",
        "    tf.keras.backend.clear_session()\n",
        "    config = tf.ConfigProto()\n",
        "    config.gpu_options.allow_growth = True\n",
        "    s = tf.InteractiveSession(config=config)\n",
        "    tf.keras.backend.set_session(s)\n",
        "    return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkqaychOpe1R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(x_train, y_train, x_test, y_test, make_model):\n",
        "  s = reset_tf_session()\n",
        "  model = make_model()\n",
        "  INIT_LR = 5e-3\n",
        "  BATCH_SIZE = 32\n",
        "  EPOCHS = 10\n",
        "  model.compile(\n",
        "      loss='categorical_crossentropy',\n",
        "      optimizer=tf.keras.optimizers.Adam(lr=INIT_LR),\n",
        "      metrics=['accuracy']\n",
        "  )\n",
        "\n",
        "  def lr_scheduler(epoch):\n",
        "      return INIT_LR * 0.9 ** epoch\n",
        "  \n",
        "  model.fit(\n",
        "      x_train, y_train,\n",
        "      batch_size=BATCH_SIZE,\n",
        "      epochs=EPOCHS,\n",
        "      callbacks=[tf.keras.callbacks.LearningRateScheduler(lr_scheduler)],\n",
        "      validation_data=(x_test, y_test),\n",
        "      shuffle=True,\n",
        "      verbose=1,\n",
        "      initial_epoch=0\n",
        "  )\n",
        "  \n",
        "train_model(x_train2, y_train2, x_test2, y_test2, make_model)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMp-gWprw63D",
        "colab_type": "text"
      },
      "source": [
        "Добавим аугментацию, используя ImageDataGenerator из preprocessing.image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ollyZq5vxDcg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(#YOUR CODE HERE)\n",
        "\n",
        "datagen.fit(x_train2)\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "def train_gen_model(train_gen, x_test, y_test, make_model):\n",
        "  s = reset_tf_session()\n",
        "  model = make_model()\n",
        "  INIT_LR = 5e-3\n",
        "  EPOCHS = 10\n",
        "  model.compile(\n",
        "      loss='categorical_crossentropy',\n",
        "      optimizer=tf.keras.optimizers.Adam(lr=INIT_LR),\n",
        "      metrics=['accuracy']\n",
        "  )\n",
        "\n",
        "  def lr_scheduler(epoch):\n",
        "      return INIT_LR * 0.9 ** epoch\n",
        "  \n",
        "  model.fit_generator(\n",
        "      train_gen,\n",
        "      steps_per_epoch = len(x_train) / BATCH_SIZE,\n",
        "      epochs=EPOCHS,\n",
        "      callbacks=[tf.keras.callbacks.LearningRateScheduler(lr_scheduler)],\n",
        "      validation_data=(x_test, y_test),\n",
        "      shuffle=True,\n",
        "      verbose=1,\n",
        "      initial_epoch=0\n",
        "  )\n",
        "  \n",
        "train_gen_model(datagen.flow(x_train2, y_train2, batch_size=BATCH_SIZE), x_test2, y_test2, make_model)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJc859FrBFA6",
        "colab_type": "text"
      },
      "source": [
        "Обратите внимание, что происходит с loss и accuracy на валидации. Сравните с предыдущим результатом."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8VM2orWou45",
        "colab_type": "text"
      },
      "source": [
        "### **2. Dropout**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJJd7ME8BM9a",
        "colab_type": "text"
      },
      "source": [
        "При обучении моделей из предыдущего пункта можно заметить, что после нескольких эпох функция потерь на тестовой выборке начинает расти (при использовании аугментации это происходит позже; как вы думаете, почему?), то есть происходит переобучение. Чтобы избежать этой проблемы, существуют различные методы, например, [Dropout](https://http://jmlr.org/papers/v15/srivastava14a.html).\n",
        "\n",
        "Идея метода заключается в том, чтобы при обучении случайно исключать из некоторых слоёв часть нейронов. Предполагается, что это уменьшит \"совместную адаптацию\" (когда одни нейроны обучаются исправлять ошибки других) и позволит избежать переобучения.\n",
        "\n",
        "Добавим в нашу модель слои Dropout."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyMyWgFdp64R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_dropout_model():\n",
        "    model = Sequential()\n",
        "    #YOUR CODE HERE\n",
        "    #используйте модель из make_model и добавьте между её слоями слои Dropout(p), где p - вероятность исключения одного нейрона\n",
        "   \n",
        "    return model\n",
        "  \n",
        "train_model(x_train2, y_train2, x_test2, y_test2, make_dropout_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElUftz9jrF7j",
        "colab_type": "text"
      },
      "source": [
        "Попробуйте поменять параметр Dropout. Как это влияет на результат?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCJeSkblrM8R",
        "colab_type": "text"
      },
      "source": [
        "### **3. Batch-нормализация**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuiH_dHjsJsD",
        "colab_type": "text"
      },
      "source": [
        "Как вы наверняка помните, нейронным сетям легче обучаться на нормализованных данных, однако после прохождения через несколько слоёв сети матожидание и дисперсия сигнала, попадающего на вход слежующим слоям, могут значительно искажаться и таким образом вносить несоответствие в градиенты разных слоёв.\n",
        "\n",
        "Метод [Batch normalization](https://arxiv.org/abs/1502.03167) предлагает нормализовать данные не только на входе, но и внутри сети.\n",
        "\n",
        "Добавим в модель слои BatchNormalization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfEBgqh_sIvc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import BatchNormalization\n",
        "\n",
        "def make_batchnorm_model():\n",
        "    #YOUR CODE HERE\n",
        "    #используйте модель из make_model и добавьте между её слоями слои BatchNormalization()\n",
        "    \n",
        "    return model\n",
        "  \n",
        "train_model(x_train2, y_train2, x_test2, y_test2, make_batchnorm_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AA--BiNvNuq",
        "colab_type": "text"
      },
      "source": [
        "### **4. L2 - регуляризация**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gklK3QjDvZQf",
        "colab_type": "text"
      },
      "source": [
        "Так же, как в случае других моделей машинного обучения, нейронные сети можно штрафовать за слишком большие веса, добавляя к функции потерь норму весов с некоторым коэффициентом. Добавить регуляризацию по весам слоя можно установкой параметра kernel_regularizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AB7wwQ6FrLyi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_model_with_l2():\n",
        "    model = Sequential()\n",
        "    #YOUR CODE HERE\n",
        "    #используйте модель из make_model и добавьте в параметры слоёв l2-регуляризацию с помощью параметра kernel_regularizer\n",
        "    #подсказка: поищите подходящий регуляризатор в tf.keras.regularizers\n",
        "    \n",
        "    return model\n",
        "\n",
        "train_model(x_train2, y_train2, x_test2, y_test2, make_model_with_l2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRzlh5K5s2k0",
        "colab_type": "text"
      },
      "source": [
        "Что будет, если увеличить коэффициент перед весами? А если уменьшить?\n",
        "\n",
        "P. S. Обратите внимание, что регуляризация замедляет скорость обучения. Улучшится ли результат, если увеличить количество эпох?"
      ]
    }
  ]
}